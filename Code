# Install necessary dependencies
!pip install ultralytics
!pip install roboflow
!pip install supervision[assets]==0.24.0

# Import necessary libraries
from roboflow import Roboflow
from ultralytics import YOLO
import supervision as sv
import numpy as np
import os

# Initialize Roboflow API to download the dataset
rf = Roboflow(api_key="your_roboflow_api_key")
project = rf.workspace("your_workspace_name").project("your_project_name")
version = project.version
dataset = version.download("yolov11")

# Train the YOLO model (if needed)
!yolo detect train data=/content/Traffic-2/data.yaml model=yolo11m.pt epochs=30 imgsz=640

# Get the current working directory
HOME = os.getcwd()
print("Current Working Directory:", HOME)

# Path to the video file you want to process
SOURCE_VIDEO_PATH = "/content/Finalvideo.mp4"

# Load the trained YOLO model
model = YOLO("/content/yolo11m.pt")

# Get the class names from the model
CLASS_NAMES_DICT = model.model.names

# Select the classes for vehicle detection
SELECTED_CLASS_NAMES = ['car', 'motorcycle', 'bus', 'truck', 'van']

# Map the class names to their respective IDs
SELECTED_CLASS_IDS = [
    {value: key for key, value in CLASS_NAMES_DICT.items()}[class_name]
    for class_name in SELECTED_CLASS_NAMES
]

# Define frame generator from the input video
frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)

# Define annotators for bounding boxes and labels
bounding_box_annotator = sv.BoxAnnotator(thickness=4)
text_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=1.5, text_color=sv.Color.BLACK)

# Get the first frame from the video
frame_iterator = iter(frame_generator)
video_frame = next(frame_iterator)

# Detect vehicles in the frame using the YOLO model
model_output = model(video_frame, verbose=False)[0]
detections = sv.Detections.from_ultralytics(model_output)

# Filter the detections to include only the selected vehicle classes
filtered_detections = detections[np.isin(detections.class_id, SELECTED_CLASS_IDS)]

# Prepare the labels for the detections
detection_labels = [
    f"{CLASS_NAMES_DICT[class_id]}: {confidence:.2f}"
    for confidence, class_id in zip(filtered_detections.confidence, filtered_detections.class_id)
]

# Annotate the video frame with bounding boxes and labels
annotated_video_frame = video_frame.copy()
annotated_video_frame = bounding_box_annotator.annotate(
    scene=annotated_video_frame, detections=filtered_detections
)
annotated_video_frame = text_annotator.annotate(
    scene=annotated_video_frame, detections=filtered_detections, labels=detection_labels
)

# Display the annotated frame
%matplotlib inline
sv.plot_image(annotated_video_frame, (16, 16))

# Define the line for vehicle counting (at the bottom of the video frame)
LINE_START = sv.Point(50, 640)
LINE_END = sv.Point(1870, 640)

# Define the output video path
TARGET_VIDEO_PATH = f"{HOME}/result.mp4"

# Initialize the ByteTrack tracker
byte_tracker = sv.ByteTrack(
    track_activation_threshold=0.25,
    lost_track_buffer=30,
    minimum_matching_threshold=0.8,
    frame_rate=30,
    minimum_consecutive_frames=3
)

# Reset the ByteTrack tracker
byte_tracker.reset()

# Create a generator for processing frames in the video
video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)
generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)

# Define the line zone for vehicle counting
line_zone = sv.LineZone(start=LINE_START, end=LINE_END)

# Define annotators for traces and bounding boxes
box_annotator = sv.BoxAnnotator(thickness=4)
label_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=1.5, text_color=sv.Color.BLACK)
trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)

# Annotator for line zone triggers
line_zone_annotator = sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)

# Callback function for processing frames
def callback(frame: np.ndarray, index: int) -> np.ndarray:
    # Run object detection on the frame
    results = model(frame, verbose=False)[0]
    detections = sv.Detections.from_ultralytics(results)
    
    # Filter detections to include only the selected classes
    detections = detections[np.isin(detections.class_id, SELECTED_CLASS_IDS)]
    
    # Update the ByteTrack tracker with the detections
    detections = byte_tracker.update_with_detections(detections)
    
    # Prepare labels with the tracker ID for each detection
    labels = [
        f"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}"
        for confidence, class_id, tracker_id in zip(detections.confidence, detections.class_id, detections.tracker_id)
    ]
    
    # Annotate the frame with traces, bounding boxes, and labels
    annotated_frame = frame.copy()
    annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)
    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)
    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)

    # Trigger the line zone for vehicle counting
    line_zone.trigger(detections)
    
    # Return the annotated frame with line zone information
    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)

# Process the video and save the annotated result
sv.process_video(
    source_path=SOURCE_VIDEO_PATH,
    target_path=TARGET_VIDEO_PATH,
    callback=callback
)
